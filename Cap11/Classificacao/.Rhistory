vetor1 <- c(1:20)
vetor1
length(vetor1)
mode(vetor1)
class(vetor1)
typeof(vetor1)
matriz1 <- matrix(1:20, nrow = 2)
matriz1
length(matriz1)
mode(matriz1)
class(matriz1)
typeof(matriz1)
array1 <- array(1:5, dim = c(3, 3, 3))
array1
length(array1)
mode(array1)
class(array1)
typeof(array1)
View(iris)
length(iris)
mode(iris)
class(iris)
typeof(iris)
lista1 <- list(a = matriz1, b = vetor1)
lista1
length(lista1)
mode(lista1)
class(lista1)
typeof(lista1)
func1 <- function(x) {
var1 <- x * x
return(var1)
}
func1(5)
class(func1)
objects()
rm(array1, func1)
objects()
array1 <- array(1:5, dim = c(3, 3, 3))
func1 <- function(x) {
var1 <- x * x
return(var1)
}
q()
str <- c("Expressões", "regulares", "em linguagem R",
"permitem a busca de padrões", "e exploração de textos",
"podemos buscar padrões em dígitos",
"como por exemplo",
"10992451280")
length(str)
str
grep("ex", str, value = F)
grep("ex", str, value = T)
grep("\\d", str, value = F)
grep("\\d", str, value = T)
grepl("\\d+", str)
grepl("\\D", str)
gsub("em", "***", str)
gsub("ex", "EX", str, ignore.case = T)
sub("em", "EM", str)
frase <- "Isso é uma string."
regexpr(pattern = "u", frase)
gregexpr(pattern = "u", frase)
str2 <- c("2678 é maior que 45 - @???!§$",
"Vamos escrever 14 scripts R")
str2
gsub("\\d", "", str2)
gsub("\\D", "", str2)
gsub("\\s", "", str2)
gsub("[iot]", "Q", str2)
gsub("[[:punct:]]", "", str2)
q()
# Configurando o diretório de trabalho
# Coloque entre aspas o diretório de trabalho que você está usando no seu computador
# Não use diretórios com espaço no nome
setwd("~/Cursos/DSA/FCD/BigDataRAzure/Cap11/Classificacao")
# Para saber qual diretório estou trabalhando
getwd()
# Lista de pacotes base carregados
search()
dados <- read.csv("~/Cursos/DSA/FCD/Scripts/Arquivos-Cap11/Classificacao/dataset.csv", stringsAsFactors = F)
str(dados)
View(dados)
dados$id = NULL
# Ajustando o label da variável alvo
dados$diagnosis = sapply(dados$diagnosis, function(x){ifelse(x == 'M', 'Maligno', 'Benigno')})
# Muitos classificadores requerem que as variáveis sejam do tipo Fator
table(dados$diagnosis)
dados$diagnosis <- factor(dados$diagnosis, levels = c('Benigno', 'Maligno'), labels = c('Benigno','Maligno'))
str(dados)
str(dados$diagnosis)
# Verificando a proporção
round(prop.table(table(dados$diagnosis)) * 100, digits = 1)
summary(dados[c("radius_mean", "area_mean", "smoothness_mean")])
summary(dados[c("radius_mean", "area_mean", "smoothness_mean")])
# Criando um função de normalização
normalizar <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
# Testando a função de normalização - os resultados devem ser idênticos
normalizar(c(1, 2, 3, 4, 5))
normalizar(c(10, 20, 30, 40, 50))
dados_norm <- as.data.frame(lapply(dados[2:31], normalizar))
View(dados_norm)
# Carregando o pacote library
# install.packages("class")
library(class)
?knn
# Criando dados de treino e dados de teste
dados_treino <- dados_norm[1:469,]
dados_teste <- dados_norm[470:569,]
# Criando os labels para os dados de treino e de teste
dados_treino_labels <- dados[1:469, 1]
dados_teste_labels <- dados[470:569, 1]
length(dados_treino_labels)
length(dados_teste_labels)
# Criando o modelo
modelo_knn_v1 <- knn(train = dados_treino,
test = dados_teste,
cl = dados_treino_labels,
k = 21)
# A função knn() retorna um objeto do tipo fator com as previsões para cada exemplo no dataset de teste
summary(modelo_knn_v1)
# Carregando o gmodels
library(gmodels)
CrossTable(x = dados_teste_labels, y = modelo_knn_v1, prop.chisq = F)
# Usando a função scale() para padronizar o z-score
?scale()
dados_z <- as.data.frame(scale(dados[-1]))
# Confirmando transformação realizada com sucesso
summary(dados_z$area_mean)
# Criando novos datasets de treino e de teste
dados_treino2 <- dados_z[1:469,]
dados_teste2 <- dados_z[470:569,]
dados_treino2_labels <- dados[1:469, 1]
dados_teste2_labels <- dados[470:569, 1]
# Reclassificando
modelo_knn_v2 <- knn(train = dados_treino2,
test = dados_teste2,
cl = dados_treino2_labels,
k = 21)
CrossTable(x = dados_teste2_labels, y = modelo_knn_v2, prop.chisq = F)
# Prepara o dataset
dados <- read.csv("~/Cursos/DSA/FCD/Scripts/Arquivos-Cap11/Classificacao/dataset.csv", stringsAsFactors = F)
dados$id = NULL
dados[,'index'] <- ifelse(ruinf(nrow(dados)) < 0.8, 1, 0)
dados[,'index'] <- ifelse(runif(nrow(dados)) < 0.8, 1, 0)
View(dados)
trainset <- dados[dados$index==1,]
testset <- dados[dados$index==0,]
# Obter o índice
trainColNum <- grep('index', names(trainset))
# Remover o índice dos datasets
trainset <- trainset[,-trainColNum]
testset <- testset[,-trainColNum]
# Obter índice de coluna da variável target no conjunto de dados
typeColNum <- grep('diag', names(dados))
library(e1071)
install.packages('e1071')
library(e1071)
?svm
modelo_svm_v1 <- svm(diagnosis ~ .,
data = trainset,
type = 'C-classification',
kernel = 'radial')
str(dados)
# Prepara o dataset
dados <- read.csv("~/Cursos/DSA/FCD/Scripts/Arquivos-Cap11/Classificacao/dataset.csv", stringsAsFactors = F)
dados$id = NULL
dados$diagnosis = sapply(dados$diagnosis, function(x){ifelse(x == 'M', 'Maligno', 'Benigno')})
table(dados$diagnosis)
dados$diagnosis <- factor(dados$diagnosis, levels = c('Benigno', 'Maligno'), labels = c('Benigno','Maligno'))
str(dados)
str(dados$diagnosis)
dados[,'index'] <- ifelse(runif(nrow(dados)) < 0.8, 1, 0)
## criação randômica do index
View(dados)
trainset <- dados[dados$index==1,]
testset <- dados[dados$index==0,]
# Obter o índice
trainColNum <- grep('index', names(trainset))
# Remover o índice dos datasets
trainset <- trainset[,-trainColNum]
testset <- testset[,-trainColNum]
# Obter índice de coluna da variável target no conjunto de dados
typeColNum <- grep('diag', names(dados))
modelo_svm_v1 <- svm(diagnosis ~ .,
data = trainset,
type = 'C-classification',
kernel = 'radial')
# Previsões nos dados de treino
pred_train <- predict(modelo_svm_v1, trainset)
# Percentual de previsões corretas com dataset de treino
mean(pred_train == trainset$diagnosis)
# Previsões nos dados de teste
pred_test <- predict(modelo_svm_v1, testset)
# Percentual de previsões corretas com dataset de teste
mean(pred_test == testset$diagnosis)
# Confusion Matrix
table(pred_test, testset$diagnosis)
# Criando o modelo
library(rpart)
modelo_rf_v1 = rpart(diagnosis ~ ., data = trainset, control = rpart.control(cp = .0005))
# Previsões nos dados de teste
tree_pred = predict(modelo_rf_v1, testset, type = 'class')
# Percentual de previsões corretas com dataset de teste
mean(tree_pred == testset$diagnosis)
# Confusion Matrix
table(tree_pred, testset$diagnosis)
# Sair
q()
